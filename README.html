<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><style>body {
  max-width: 980px;
  border: 1px solid #ddd;
  outline: 1300px solid #fff;
  margin: 16px auto;
}

body .markdown-body
{
  padding: 45px;
}

@font-face {
  font-family: fontawesome-mini;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

.markdown-body {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  color: #333333;
  overflow: hidden;
  font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif;
  font-size: 16px;
  line-height: 1.6;
  word-wrap: break-word;
}

.markdown-body a {
  background: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline: 0;
}

.markdown-body b,
.markdown-body strong {
  font-weight: bold;
}

.markdown-body mark {
  background: #ff0;
  color: #000;
  font-style: italic;
  font-weight: bold;
}

.markdown-body sub,
.markdown-body sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
.markdown-body sup {
  top: -0.5em;
}
.markdown-body sub {
  bottom: -0.25em;
}

.markdown-body h1 {
  font-size: 2em;
  margin: 0.67em 0;
}

.markdown-body img {
  border: 0;
}

.markdown-body hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}

.markdown-body pre {
  overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre,
.markdown-body samp {
  font-family: monospace, monospace;
  font-size: 1em;
}

.markdown-body input {
  color: inherit;
  font: inherit;
  margin: 0;
}

.markdown-body html input[disabled] {
  cursor: default;
}

.markdown-body input {
  line-height: normal;
}

.markdown-body input[type="checkbox"] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body .codehilitetable {
  border: 0;
  border-spacing: 0;
}

.markdown-body .codehilitetable tr {
  border: 0;
}

.markdown-body .codehilitetable pre,
.markdown-body .codehilitetable div.codehilite {
  margin: 0;
}

.markdown-body .linenos,
.markdown-body .code,
.markdown-body .codehilitetable td {
  border: 0;
  padding: 0;
}

.markdown-body td:not(.linenos) .linenodiv {
  padding: 0 !important;
}

.markdown-body .code {
  width: 100%;
}

.markdown-body .linenos div pre,
.markdown-body .linenodiv pre,
.markdown-body .linenodiv {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-left-radius: 3px;
  -webkit-border-bottom-left-radius: 3px;
  -moz-border-radius-topleft: 3px;
  -moz-border-radius-bottomleft: 3px;
  border-top-left-radius: 3px;
  border-bottom-left-radius: 3px;
}

.markdown-body .code div pre,
.markdown-body .code div {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-right-radius: 3px;
  -webkit-border-bottom-right-radius: 3px;
  -moz-border-radius-topright: 3px;
  -moz-border-radius-bottomright: 3px;
  border-top-right-radius: 3px;
  border-bottom-right-radius: 3px;
}

.markdown-body * {
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body input {
  font: 13px Helvetica, arial, freesans, clean, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol";
  line-height: 1.4;
}

.markdown-body a {
  color: #4183c4;
  text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:focus,
.markdown-body a:active {
  text-decoration: underline;
}

.markdown-body hr {
  height: 0;
  margin: 15px 0;
  overflow: hidden;
  background: transparent;
  border: 0;
  border-bottom: 1px solid #ddd;
}

.markdown-body hr:before,
.markdown-body hr:after {
  display: table;
  content: " ";
}

.markdown-body hr:after {
  clear: both;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 15px;
  margin-bottom: 15px;
  line-height: 1.1;
}

.markdown-body h1 {
  font-size: 30px;
}

.markdown-body h2 {
  font-size: 21px;
}

.markdown-body h3 {
  font-size: 16px;
}

.markdown-body h4 {
  font-size: 14px;
}

.markdown-body h5 {
  font-size: 12px;
}

.markdown-body h6 {
  font-size: 11px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ul,
.markdown-body ol {
  padding: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre,
.markdown-body samp {
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body kbd {
  background-color: #e7e7e7;
  background-image: -moz-linear-gradient(#fefefe, #e7e7e7);
  background-image: -webkit-linear-gradient(#fefefe, #e7e7e7);
  background-image: linear-gradient(#fefefe, #e7e7e7);
  background-repeat: repeat-x;
  border-radius: 2px;
  border: 1px solid #cfcfcf;
  color: #000;
  padding: 3px 5px;
  line-height: 10px;
  font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
  display: inline-block;
}

.markdown-body>*:first-child {
  margin-top: 0 !important;
}

.markdown-body>*:last-child {
  margin-bottom: 0 !important;
}

.markdown-body .headerlink {
  font: normal 400 16px fontawesome-mini;
  vertical-align: middle;
  margin-left: -16px;
  float: left;
  display: inline-block;
  text-decoration: none;
  opacity: 0;
  color: #333;
}

.markdown-body .headerlink:focus {
  outline: none;
}

.markdown-body h1 .headerlink {
  margin-top: 0.8rem;
}

.markdown-body h2 .headerlink,
.markdown-body h3 .headerlink {
  margin-top: 0.6rem;
}

.markdown-body h4 .headerlink {
  margin-top: 0.2rem;
}

.markdown-body h5 .headerlink,
.markdown-body h6 .headerlink {
  margin-top: 0;
}

.markdown-body .headerlink:hover,
.markdown-body h1:hover .headerlink,
.markdown-body h2:hover .headerlink,
.markdown-body h3:hover .headerlink,
.markdown-body h4:hover .headerlink,
.markdown-body h5:hover .headerlink,
.markdown-body h6:hover .headerlink {
  opacity: 1;
  text-decoration: none;
}

.markdown-body h1 {
  padding-bottom: 0.3em;
  font-size: 2.25em;
  line-height: 1.2;
  border-bottom: 1px solid #eee;
}

.markdown-body h2 {
  padding-bottom: 0.3em;
  font-size: 1.75em;
  line-height: 1.225;
  border-bottom: 1px solid #eee;
}

.markdown-body h3 {
  font-size: 1.5em;
  line-height: 1.43;
}

.markdown-body h4 {
  font-size: 1.25em;
}

.markdown-body h5 {
  font-size: 1em;
}

.markdown-body h6 {
  font-size: 1em;
  color: #777;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre,
.markdown-body .admonition {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: 4px;
  padding: 0;
  margin: 16px 0;
  background-color: #e7e7e7;
  border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
  padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: bold;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body blockquote {
  padding: 0 15px;
  color: #777;
  border-left: 4px solid #ddd;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}

.markdown-body table th {
  font-weight: bold;
}

.markdown-body table th,
.markdown-body table td {
  padding: 6px 13px;
  border: 1px solid #ddd;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

.markdown-body img {
  max-width: 100%;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body code,
.markdown-body samp {
  padding: 0;
  padding-top: 0.2em;
  padding-bottom: 0.2em;
  margin: 0;
  font-size: 85%;
  background-color: rgba(0,0,0,0.04);
  border-radius: 3px;
}

.markdown-body code:before,
.markdown-body code:after {
  letter-spacing: -0.2em;
  content: "\00a0";
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
  font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .codehilite {
  margin-bottom: 16px;
}

.markdown-body .codehilite pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  background-color: #f7f7f7;
  border-radius: 3px;
}

.markdown-body .codehilite pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre code {
  display: inline;
  max-width: initial;
  padding: 0;
  margin: 0;
  overflow: initial;
  line-height: inherit;
  word-wrap: normal;
  background-color: transparent;
  border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
  content: normal;
}

/* Admonition */
.markdown-body .admonition {
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  position: relative;
  border-radius: 3px;
  border: 1px solid #e0e0e0;
  border-left: 6px solid #333;
  padding: 10px 10px 10px 30px;
}

.markdown-body .admonition table {
  color: #333;
}

.markdown-body .admonition p {
  padding: 0;
}

.markdown-body .admonition-title {
  font-weight: bold;
  margin: 0;
}

.markdown-body .admonition>.admonition-title {
  color: #333;
}

.markdown-body .attention>.admonition-title {
  color: #a6d796;
}

.markdown-body .caution>.admonition-title {
  color: #d7a796;
}

.markdown-body .hint>.admonition-title {
  color: #96c6d7;
}

.markdown-body .danger>.admonition-title {
  color: #c25f77;
}

.markdown-body .question>.admonition-title {
  color: #96a6d7;
}

.markdown-body .note>.admonition-title {
  color: #d7c896;
}

.markdown-body .admonition:before,
.markdown-body .attention:before,
.markdown-body .caution:before,
.markdown-body .hint:before,
.markdown-body .danger:before,
.markdown-body .question:before,
.markdown-body .note:before {
  font: normal normal 16px fontawesome-mini;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  line-height: 1.5;
  color: #333;
  position: absolute;
  left: 0;
  top: 0;
  padding-top: 10px;
  padding-left: 10px;
}

.markdown-body .admonition:before {
  content: "\f056\00a0";
  color: 333;
}

.markdown-body .attention:before {
  content: "\f058\00a0";
  color: #a6d796;
}

.markdown-body .caution:before {
  content: "\f06a\00a0";
  color: #d7a796;
}

.markdown-body .hint:before {
  content: "\f05a\00a0";
  color: #96c6d7;
}

.markdown-body .danger:before {
  content: "\f057\00a0";
  color: #c25f77;
}

.markdown-body .question:before {
  content: "\f059\00a0";
  color: #96a6d7;
}

.markdown-body .note:before {
  content: "\f040\00a0";
  color: #d7c896;
}

.markdown-body .admonition::after {
  content: normal;
}

.markdown-body .attention {
  border-left: 6px solid #a6d796;
}

.markdown-body .caution {
  border-left: 6px solid #d7a796;
}

.markdown-body .hint {
  border-left: 6px solid #96c6d7;
}

.markdown-body .danger {
  border-left: 6px solid #c25f77;
}

.markdown-body .question {
  border-left: 6px solid #96a6d7;
}

.markdown-body .note {
  border-left: 6px solid #d7c896;
}

.markdown-body .admonition>*:first-child {
  margin-top: 0 !important;
}

.markdown-body .admonition>*:last-child {
  margin-bottom: 0 !important;
}

/* progress bar*/
.markdown-body .progress {
  display: block;
  width: 300px;
  margin: 10px 0;
  height: 24px;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #ededed;
  position: relative;
  box-shadow: inset -1px 1px 3px rgba(0, 0, 0, .1);
}

.markdown-body .progress-label {
  position: absolute;
  text-align: center;
  font-weight: bold;
  width: 100%; margin: 0;
  line-height: 24px;
  color: #333;
  text-shadow: 1px 1px 0 #fefefe, -1px -1px 0 #fefefe, -1px 1px 0 #fefefe, 1px -1px 0 #fefefe, 0 1px 0 #fefefe, 0 -1px 0 #fefefe, 1px 0 0 #fefefe, -1px 0 0 #fefefe, 1px 1px 2px #000;
  -webkit-font-smoothing: antialiased !important;
  white-space: nowrap;
  overflow: hidden;
}

.markdown-body .progress-bar {
  height: 24px;
  float: left;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #96c6d7;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, .5), inset 0 -1px 0 rgba(0, 0, 0, .1);
  background-size: 30px 30px;
  background-image: -webkit-linear-gradient(
    135deg, rgba(255, 255, 255, .4) 27%,
    transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%,
    transparent 77%, transparent
  );
  background-image: -moz-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -ms-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -o-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
}

.markdown-body .progress-100plus .progress-bar {
  background-color: #a6d796;
}

.markdown-body .progress-80plus .progress-bar {
  background-color: #c6d796;
}

.markdown-body .progress-60plus .progress-bar {
  background-color: #d7c896;
}

.markdown-body .progress-40plus .progress-bar {
  background-color: #d7a796;
}

.markdown-body .progress-20plus .progress-bar {
  background-color: #d796a6;
}

.markdown-body .progress-0plus .progress-bar {
  background-color: #c25f77;
}

.markdown-body .candystripe-animate .progress-bar{
  -webkit-animation: animate-stripes 3s linear infinite;
  -moz-animation: animate-stripes 3s linear infinite;
  animation: animate-stripes 3s linear infinite;
}

@-webkit-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@-moz-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

.markdown-body .gloss .progress-bar {
  box-shadow:
    inset 0 4px 12px rgba(255, 255, 255, .7),
    inset 0 -12px 0 rgba(0, 0, 0, .05);
}

/* MultiMarkdown Critic Blocks */
.markdown-body .critic_mark {
  background: #ff0;
}

.markdown-body .critic_delete {
  color: #c82829;
  text-decoration: line-through;
}

.markdown-body .critic_insert {
  color: #718c00 ;
  text-decoration: underline;
}

.markdown-body .critic_comment {
  color: #8e908c;
  font-style: italic;
}

.markdown-body .headeranchor {
  font: normal normal 16px fontawesome-mini;
  line-height: 1;
  display: inline-block;
  text-decoration: none;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.headeranchor:before {
  content: '\e157';
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 4px 0.25em -20px;
  vertical-align: middle;
}

/* Media */
@media only screen and (min-width: 480px) {
  .markdown-body {
    font-size:14px;
  }
}

@media only screen and (min-width: 768px) {
  .markdown-body {
    font-size:16px;
  }
}

@media print {
  .markdown-body * {
    background: transparent !important;
    color: black !important;
    filter:none !important;
    -ms-filter: none !important;
  }

  .markdown-body {
    font-size:12pt;
    max-width:100%;
    outline:none;
    border: 0;
  }

  .markdown-body a,
  .markdown-body a:visited {
    text-decoration: underline;
  }

  .markdown-body .headeranchor-link {
    display: none;
  }

  .markdown-body a[href]:after {
    content: " (" attr(href) ")";
  }

  .markdown-body abbr[title]:after {
    content: " (" attr(title) ")";
  }

  .markdown-body .ir a:after,
  .markdown-body a[href^="javascript:"]:after,
  .markdown-body a[href^="#"]:after {
    content: "";
  }

  .markdown-body pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .markdown-body pre,
  .markdown-body blockquote {
    border: 1px solid #999;
    padding-right: 1em;
    page-break-inside: avoid;
  }

  .markdown-body .progress,
  .markdown-body .progress-bar {
    -moz-box-shadow: none;
    -webkit-box-shadow: none;
    box-shadow: none;
  }

  .markdown-body .progress {
    border: 1px solid #ddd;
  }

  .markdown-body .progress-bar {
    height: 22px;
    border-right: 1px solid #ddd;
  }

  .markdown-body tr,
  .markdown-body img {
    page-break-inside: avoid;
  }

  .markdown-body img {
    max-width: 100% !important;
  }

  .markdown-body p,
  .markdown-body h2,
  .markdown-body h3 {
    orphans: 3;
    widows: 3;
  }

  .markdown-body h2,
  .markdown-body h3 {
    page-break-after: avoid;
  }
}
</style><style>/*GitHub*/
.codehilite {background-color:#fff;color:#333333;}
.codehilite .hll {background-color:#ffffcc;}
.codehilite .c{color:#999988;font-style:italic}
.codehilite .err{color:#a61717;background-color:#e3d2d2}
.codehilite .k{font-weight:bold}
.codehilite .o{font-weight:bold}
.codehilite .cm{color:#999988;font-style:italic}
.codehilite .cp{color:#999999;font-weight:bold}
.codehilite .c1{color:#999988;font-style:italic}
.codehilite .cs{color:#999999;font-weight:bold;font-style:italic}
.codehilite .gd{color:#000000;background-color:#ffdddd}
.codehilite .ge{font-style:italic}
.codehilite .gr{color:#aa0000}
.codehilite .gh{color:#999999}
.codehilite .gi{color:#000000;background-color:#ddffdd}
.codehilite .go{color:#888888}
.codehilite .gp{color:#555555}
.codehilite .gs{font-weight:bold}
.codehilite .gu{color:#800080;font-weight:bold}
.codehilite .gt{color:#aa0000}
.codehilite .kc{font-weight:bold}
.codehilite .kd{font-weight:bold}
.codehilite .kn{font-weight:bold}
.codehilite .kp{font-weight:bold}
.codehilite .kr{font-weight:bold}
.codehilite .kt{color:#445588;font-weight:bold}
.codehilite .m{color:#009999}
.codehilite .s{color:#dd1144}
.codehilite .n{color:#333333}
.codehilite .na{color:teal}
.codehilite .nb{color:#0086b3}
.codehilite .nc{color:#445588;font-weight:bold}
.codehilite .no{color:teal}
.codehilite .ni{color:purple}
.codehilite .ne{color:#990000;font-weight:bold}
.codehilite .nf{color:#990000;font-weight:bold}
.codehilite .nn{color:#555555}
.codehilite .nt{color:navy}
.codehilite .nv{color:teal}
.codehilite .ow{font-weight:bold}
.codehilite .w{color:#bbbbbb}
.codehilite .mf{color:#009999}
.codehilite .mh{color:#009999}
.codehilite .mi{color:#009999}
.codehilite .mo{color:#009999}
.codehilite .sb{color:#dd1144}
.codehilite .sc{color:#dd1144}
.codehilite .sd{color:#dd1144}
.codehilite .s2{color:#dd1144}
.codehilite .se{color:#dd1144}
.codehilite .sh{color:#dd1144}
.codehilite .si{color:#dd1144}
.codehilite .sx{color:#dd1144}
.codehilite .sr{color:#009926}
.codehilite .s1{color:#dd1144}
.codehilite .ss{color:#990073}
.codehilite .bp{color:#999999}
.codehilite .vc{color:teal}
.codehilite .vg{color:teal}
.codehilite .vi{color:teal}
.codehilite .il{color:#009999}
.codehilite .gc{color:#999;background-color:#EAF2F5}
</style><title>README</title></head><body><article class="markdown-body"><p align="center"><img width="40%" src="/home/ritchie/codes/the-incredible-pytorch/the_incredible_pytorch.png" /></p>

<hr />
<p><p align="center">
    <img src="https://img.shields.io/badge/stars-3700+-blue.svg"/>
    <img src="https://img.shields.io/badge/forks-700+-blue.svg"/>
    <img src="https://img.shields.io/badge/license-MIT-blue.svg"/>
</p></p>
<p>This is a curated list of tutorials, projects, libraries, videos, papers, books and anything related to the incredible <a href="http://pytorch.org/">PyTorch</a>. Feel free to make a pull request to contribute to this list.</p>
<h2 id="tutorials">Tutorials<a class="headerlink" href="#tutorials" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/pytorch/tutorials">Official PyTorch Tutorials</a></li>
<li><a href="https://github.com/pytorch/examples">Official PyTorch Examples</a></li>
<li><a href="https://github.com/ritchieng/deep-learning-wizard">Practical Deep Learning with PyTorch</a></li>
<li><a href="https://github.com/rasbt/deeplearning-models">Deep Learning Models</a></li>
<li><a href="https://github.com/jcjohnson/pytorch-examples">Simple Examples to Introduce PyTorch</a></li>
<li><a href="https://github.com/vinhkhuc/PyTorch-Mini-Tutorials">Mini Tutorials in PyTorch</a></li>
<li><a href="https://github.com/rguthrie3/DeepLearningForNLPInPytorch">Deep Learning for NLP</a></li>
<li><a href="https://github.com/yunjey/pytorch-tutorial">Deep Learning Tutorial for Researchers</a></li>
<li><a href="https://github.com/wkentaro/pytorch-fcn">Fully Convolutional Networks implemented with PyTorch</a></li>
<li><a href="https://github.com/hunkim/PyTorchZeroToAll">Simple PyTorch Tutorials Zero to ALL</a></li>
<li><a href="https://github.com/DSKSD/DeepNLP-models-Pytorch">DeepNLP-models-Pytorch</a></li>
<li><a href="https://github.com/mila-udem/welcome_tutorials">MILA PyTorch Welcome Tutorials</a></li>
<li><a href="https://github.com/spro/practical-pytorch">Practical PyTorch</a></li>
<li><a href="https://github.com/moemen95/PyTorch-Project-Template">PyTorch Project Template</a><ul>
<li>A scalable template for PyTorch projects, with examples in Image Segmentation, Object classification, GANs and Reinforcement Learning.</li>
<li><a href="https://github.com/moemen95/PyTorch-Project-Template/blob/master/tutorials/getStarted_tutorial.md">Get started Tutorial</a></li>
<li><a href="https://github.com/moemen95/PyTorch-Project-Template/blob/master/tutorials/mnist_tutorial.md">Mnist Tutorial</a></li>
<li><a href="https://github.com/moemen95/PyTorch-Project-Template/blob/master/agents/erfnet.py">ERFNET</a></li>
<li><a href="https://github.com/moemen95/PyTorch-Project-Template/blob/master/agents/dcgan.py">DCGAN</a></li>
<li><a href="https://github.com/moemen95/PyTorch-Project-Template/blob/master/agents/dqn.py">DQN</a></li>
</ul>
</li>
</ul>
<h2 id="visualization">Visualization<a class="headerlink" href="#visualization" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/tomgoldstein/loss-landscape">Loss Visualization</a></li>
<li><a href="https://github.com/jacobgil/pytorch-grad-cam">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</a></li>
<li><a href="https://github.com/utkuozbulak/pytorch-cnn-visualizations">Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</a></li>
<li><a href="https://github.com/utkuozbulak/pytorch-cnn-visualizations">SmoothGrad: removing noise by adding noise</a></li>
</ul>
<h2 id="explainability">Explainability<a class="headerlink" href="#explainability" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/csinva/hierarchical-dnn-interpretations">Hierarchical interpretations for neural network predictions</a></li>
<li><a href="https://github.com/slundberg/shap">Shap, a unified approach to explain the output of any machine learning model</a></li>
<li><a href="https://github.com/lutzroeder/netron">VIsualizing PyTorch saved .pth deep learning models with netron</a></li>
<li><a href="https://github.com/kimhc6028/soft-decision-tree">Distilling a Neural Network Into a Soft Decision Tree</a></li>
</ul>
<h2 id="object-detection">Object Detection<a class="headerlink" href="#object-detection" title="Permanent link"></a></h2>
<ul>
<li><a href="https://www.google.com/search?q=yolo+v3+pytorc&amp;oq=yolo+v3+pytorc&amp;aqs=chrome..69i57j69i60l3j69i59.2355j0j4&amp;sourceid=chrome&amp;ie=UTF-8">YOLOv3</a></li>
<li><a href="https://github.com/longcw/yolo2-pytorch">YOLOv2: Real-Time Object Detection</a></li>
<li><a href="https://github.com/amdegroot/ssd.pytorch">SSD: Single Shot MultiBox Detector</a></li>
<li><a href="https://github.com/ignacio-rocco/detectorch">Detectron models for Object Detection</a></li>
<li><a href="https://github.com/potterhsu/SVHNClassifier-PyTorch">Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks</a></li>
<li><a href="https://github.com/TarinZ/whale-detector">Whale Detector</a></li>
</ul>
<h2 id="long-tailed-recognition">Long-Tailed Recognition<a class="headerlink" href="#long-tailed-recognition" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/zhmiao/OpenLongTailRecognition-OLTR">Large-Scale Long-Tailed Recognition in an Open World</a></li>
<li><a href="https://github.com/ShiyuLiang/odin-pytorch">Principled Detection of Out-of-Distribution Examples in Neural Networks</a></li>
<li><a href="https://github.com/uoguelph-mlrg/confidence_estimation">Learning Confidence for Out-of-Distribution Detection in Neural Networks</a></li>
</ul>
<h2 id="energy-based-learning">Energy-Based Learning<a class="headerlink" href="#energy-based-learning" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/ebgan/ebgan.py">EBGAN, Energy-Based GANs</a></li>
<li><a href="https://github.com/ritheshkumar95/energy_based_generative_models">Maximum Entropy Generators for Energy-based Models</a></li>
</ul>
<h2 id="missing-data">Missing Data<a class="headerlink" href="#missing-data" title="Permanent link"></a></h2>
<ul>
<li><a href="http://papers.nips.cc/paper/7911-brits-bidirectional-recurrent-imputation-for-time-series">BRITS: Bidirectional Recurrent Imputation for Time Series</a></li>
</ul>
<h2 id="architecture-search">Architecture Search<a class="headerlink" href="#architecture-search" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/quark0/darts">DARTS: Differentiable Architecture Search</a></li>
<li><a href="https://github.com/zsef123/EfficientNets-PyTorch">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a></li>
</ul>
<h2 id="optimization">Optimization<a class="headerlink" href="#optimization" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/Luolc/AdaBound">AdaBound, Train As Fast as Adam As Good as SGD</a></li>
<li><a href="https://github.com/ferrine/geoopt">Riemannian Adaptive Optimization Methods</a></li>
<li><a href="https://github.com/hjmshi/PyTorch-LBFGS">L-BFGS</a></li>
<li><a href="https://github.com/locuslab/optnet">OptNet: Differentiable Optimization as a Layer in Neural Networks</a></li>
<li><a href="https://github.com/ikostrikov/pytorch-meta-optimizer">Learning to learn by gradient descent by gradient descent</a></li>
</ul>
<h2 id="quantum-machine-learning">Quantum Machine Learning<a class="headerlink" href="#quantum-machine-learning" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/kaihsin/Tor10">Tor10, generic tensor-network library for quantum simulation in PyTorch</a></li>
<li><a href="https://github.com/XanaduAI/pennylane">PennyLane, cross-platform Python library for quantum machine learning with PyTorch interface</a></li>
</ul>
<h2 id="neural-network-compression">Neural Network Compression<a class="headerlink" href="#neural-network-compression" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/KarenUllrich/Tutorial_BayesianCompressionForDL">Bayesian Compression for Deep Learning</a></li>
<li><a href="https://github.com/NervanaSystems/distiller">Neural Network Distiller by Intel AI Lab: a Python package for neural network compression research</a></li>
<li><a href="https://github.com/hyang1990/model_based_energy_constrained_compression">Energy-constrained Compression for Deep Neural Networks via Weighted Sparse Projection and Layer Input Masking</a></li>
<li><a href="https://github.com/alecwangcq/EigenDamage-Pytorch">EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis</a></li>
<li><a href="https://github.com/jacobgil/pytorch-pruning">Pruning Convolutional Neural Networks for Resource Efficient Inference</a></li>
<li><a href="https://github.com/BayesWatch/pytorch-prunes">Pruning neural networks: is it time to nip it in the bud? (showing reduced networks work better)</a></li>
</ul>
<h2 id="facial-action-and-pose-recognition">Facial, Action and Pose Recognition<a class="headerlink" href="#facial-action-and-pose-recognition" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/AaltoVision/DGC-Net">DGC-Net: Dense Geometric Correspondence Network</a></li>
<li><a href="https://github.com/ZhaoJ9014/face.evoLVe.PyTorch">High performance facial recognition library on PyTorch</a></li>
<li><a href="https://github.com/zisianw/FaceBoxes.PyTorch">FaceBoxes, a CPU real-time face detector with high accuracy</a></li>
<li><a href="https://github.com/1adrianb/face-alignment">How far are we from solving the 2D &amp; 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)</a></li>
<li><a href="https://github.com/kenshohara/3D-ResNets-PyTorch">Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition</a></li>
<li><a href="https://github.com/DavexPro/pytorch-pose-estimation">PyTorch Realtime Multi-Person Pose Estimation</a></li>
<li><a href="https://github.com/clcarwin/sphereface_pytorch">SphereFace: Deep Hypersphere Embedding for Face Recognition</a></li>
<li><a href="https://github.com/albertpumarola/GANimation">GANimation: Anatomically-aware Facial Animation from a Single Image</a></li>
<li><a href="https://github.com/ericsun99/Shufflenet-v2-Pytorch">Shufflenet V2 by Face++ with better results than paper</a></li>
<li><a href="https://github.com/xingyizhou/pytorch-pose-hg-3d">Towards 3D Human Pose Estimation in the Wild: a Weakly-supervised Approach</a></li>
<li><a href="https://github.com/ClementPinard/SfmLearner-Pytorch">Unsupervised Learning of Depth and Ego-Motion from Video</a></li>
<li><a href="https://github.com/NVIDIA/flownet2-pytorch">FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks</a></li>
<li><a href="https://github.com/ClementPinard/FlowNetPytorch">FlowNet: Learning Optical Flow with Convolutional Networks</a></li>
<li><a href="https://github.com/sniklaus/pytorch-spynet">Optical Flow Estimation using a Spatial Pyramid Network</a></li>
<li><a href="https://github.com/thnkim/OpenFacePytorch">OpenFace in PyTorch</a></li>
<li><a href="https://github.com/grib0ed0v/face_recognition.pytorch">Deep Face Recognition in PyTorch</a></li>
</ul>
<h2 id="super-resolution">Super resolution<a class="headerlink" href="#super-resolution" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/thstkdgus35/EDSR-PyTorch">Enhanced Deep Residual Networks for Single Image Super-Resolution</a></li>
<li><a href="https://github.com/pytorch/examples/tree/master/super_resolution">Superresolution using an efficient sub-pixel convolutional neural network</a></li>
<li><a href="https://github.com/bengxy/FastNeuralStyle">Perceptual Losses for Real-Time Style Transfer and Super-Resolution</a></li>
</ul>
<h2 id="voice">Voice<a class="headerlink" href="#voice" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/mindslab-ai/voicefilter">Google AI VoiceFilter: Targeted Voice Separatation by Speaker-Conditioned Spectrogram Masking</a></li>
</ul>
<h2 id="medical">Medical<a class="headerlink" href="#medical" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/mateuszbuda/brain-segmentation-pytorch">U-Net for FLAIR Abnormality Segmentation in Brain MRI</a></li>
<li><a href="https://github.com/kheyer/Genomic-ULMFiT">Genomic Classification via ULMFiT</a></li>
<li><a href="https://github.com/nyukat/breast_cancer_classifier">Deep Neural Networks Improve Radiologists&rsquo; Performance in Breast Cancer Screening</a></li>
<li><a href="https://github.com/justusschock/delira">Delira, lightweight framework for medical imaging prototyping</a></li>
<li><a href="https://github.com/mattmacy/vnet.pytorch">V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation</a></li>
<li><a href="https://github.com/perone/medicaltorch">Medical Torch, medical imaging framework for PyTorch</a></li>
</ul>
<h2 id="3d-segmentation-classification-and-regression">3D Segmentation, Classification and Regression<a class="headerlink" href="#3d-segmentation-classification-and-regression" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/fxia22/pointnet.pytorch">PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</a></li>
</ul>
<h2 id="video-recognition">Video Recognition<a class="headerlink" href="#video-recognition" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/nv-tlabs/STEAL">Devil Is in the Edges: Learning Semantic Boundaries from Noisy Annotations</a></li>
<li><a href="https://github.com/AKSHAYUBHAT/DeepVideoAnalytics">Deep Video Analytics</a></li>
</ul>
<h2 id="recurrent-neural-networks-rnns">Recurrent Neural Networks (RNNs)<a class="headerlink" href="#recurrent-neural-networks-rnns" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/yikangshen/Ordered-Neurons">Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks</a></li>
<li><a href="https://github.com/salesforce/awd-lstm-lm">Averaged Stochastic Gradient Descent with Weight Dropped LSTM</a></li>
<li><a href="https://github.com/taolei87/sru">Training RNNs as Fast as CNNs</a></li>
<li><a href="https://github.com/salesforce/pytorch-qrnn">Quasi-Recurrent Neural Network (QRNN)</a></li>
<li><a href="https://github.com/Wizaron/reseg-pytorch">ReSeg: A Recurrent Neural Network-based Model for Semantic Segmentation</a></li>
<li><a href="https://github.com/emited/VariationalRecurrentNeuralNetwork">A Recurrent Latent Variable Model for Sequential Data (VRNN)</a></li>
<li><a href="https://github.com/dasguptar/treelstm.pytorch">Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks</a></li>
<li><a href="https://github.com/DSKSD/RNN-for-Joint-NLU">Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling</a></li>
<li><a href="https://github.com/sanyam5/arc-pytorch">Attentive Recurrent Comparators</a></li>
<li><a href="https://github.com/MaximumEntropy/Seq2Seq-PyTorch">Collection of Sequence to Sequence Models with PyTorch</a><ol>
<li>Vanilla Sequence to Sequence models</li>
<li>Attention based Sequence to Sequence models</li>
<li>Faster attention mechanisms using dot products between the final encoder and decoder hidden states</li>
</ol>
</li>
</ul>
<h2 id="convolutional-neural-networks-cnns">Convolutional Neural Networks (CNNs)<a class="headerlink" href="#convolutional-neural-networks-cnns" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/ranahanocka/MeshCNN">MeshCNN, a convolutional neural network designed specifically for triangular meshes</a></li>
<li><a href="https://github.com/d-li14/octconv.pytorch">Octave Convolution</a></li>
<li><a href="https://github.com/rwightman/pytorch-image-models">PyTorch Image Models, ResNet/ResNeXT, DPN, MobileNet-V3/V2/V1, MNASNet, Single-Path NAS, FBNet</a></li>
<li><a href="https://github.com/shrubb/box-convolutions">Deep Neural Networks with Box Convolutions</a></li>
<li><a href="https://github.com/jarrelscy/iResnet">Invertible Residual Networks</a></li>
<li><a href="https://github.com/xternalz/SDPoint">Stochastic Downsampling for Cost-Adjustable Inference and Improved Regularization in Convolutional Networks </a></li>
<li><a href="https://github.com/jwyang/faster-rcnn.pytorch">Faster Faster R-CNN Implementation</a><ul>
<li><a href="https://github.com/longcw/faster_rcnn_pytorch">Faster R-CNN Another Implementation</a></li>
</ul>
</li>
<li><a href="https://github.com/szagoruyko/attention-transfer">Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer</a></li>
<li><a href="https://github.com/szagoruyko/functional-zoo">Wide ResNet model in PyTorch</a>
    -<a href="https://github.com/szagoruyko/diracnets">DiracNets: Training Very Deep Neural Networks Without Skip-Connections</a></li>
<li><a href="https://github.com/bgshih/crnn">An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition</a></li>
<li><a href="https://github.com/gpleiss/efficient_densenet_pytorch">Efficient Densenet</a></li>
<li><a href="https://github.com/sniklaus/pytorch-sepconv">Video Frame Interpolation via Adaptive Separable Convolution</a></li>
<li><a href="https://github.com/edgarriba/examples/tree/master/triplet">Learning local feature descriptors with triplets and shallow convolutional neural networks</a></li>
<li><a href="https://github.com/bamos/densenet.pytorch">Densely Connected Convolutional Networks</a></li>
<li><a href="https://github.com/jcjohnson/pytorch-vgg">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></li>
<li><a href="https://github.com/gsp-27/pytorch_Squeezenet">SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and \&lt;0.5MB model size</a></li>
<li><a href="https://github.com/szagoruyko/functional-zoo">Deep Residual Learning for Image Recognition</a></li>
<li><a href="https://github.com/xternalz/WideResNet-pytorch">Training Wide ResNets for CIFAR-10 and CIFAR-100 in PyTorch</a></li>
<li><a href="https://github.com/oeway/pytorch-deform-conv">Deformable Convolutional Network</a></li>
<li><a href="https://github.com/vabh/convolutional-neural-fabrics">Convolutional Neural Fabrics</a></li>
<li><a href="https://github.com/1zb/deformable-convolution-pytorch">Deformable Convolutional Networks in PyTorch</a></li>
<li><a href="https://github.com/fyu/drn">Dilated ResNet combination with Dilated Convolutions</a></li>
<li><a href="https://github.com/utkuozbulak/pytorch-cnn-visualizations">Striving for Simplicity: The All Convolutional Net</a></li>
<li><a href="https://github.com/automan000/Convolution_LSTM_pytorch">Convolutional LSTM Network</a></li>
<li><a href="https://github.com/osmr/imgclsmob">Big collection of pretrained classification models</a></li>
<li><a href="https://github.com/rdcolema/pytorch-image-classification">PyTorch Image Classification with Kaggle Dogs vs Cats Dataset</a></li>
<li><a href="https://github.com/kuangliu/pytorch-cifar">CIFAR-10 on Pytorch with VGG, ResNet and DenseNet</a></li>
<li><a href="https://github.com/aaron-xichen/pytorch-playground">Base pretrained models and datasets in pytorch (MNIST, SVHN, CIFAR10, CIFAR100, STL10, AlexNet, VGG16, VGG19, ResNet, Inception, SqueezeNet)</a></li>
</ul>
<h2 id="segmentation">Segmentation<a class="headerlink" href="#segmentation" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/bodokaiser/piwise">Pixel-wise Segmentation on VOC2012 Dataset using PyTorch</a></li>
<li><a href="https://github.com/achaiah/pywick">Pywick - High-level batteries-included neural network training library for Pytorch</a></li>
<li><a href="https://github.com/NVIDIA/semantic-segmentation">Improving Semantic Segmentation via Video Propagation and Label Relaxation</a></li>
</ul>
<h2 id="graph">Graph<a class="headerlink" href="#graph" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/benedekrozemberczki/SGCN">Signed Graph Convolutional Neural Network</a></li>
<li><a href="https://github.com/HongyangGao/gunet">Graph U-Nets</a></li>
<li><a href="https://github.com/benedekrozemberczki/ClusterGCN">Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks</a></li>
<li><a href="https://github.com/benedekrozemberczki/MixHop-and-N-GCN">MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing</a></li>
<li><a href="https://github.com/benedekrozemberczki/SEAL-CI">Semi-Supervised Graph Classification: A Hierarchical Graph Perspective</a></li>
<li><a href="https://github.com/facebookresearch/PyTorch-BigGraph">PyTorch BigGraph by FAIR for Generating Embeddings From Large-scale Graph Data</a></li>
<li><a href="https://github.com/benedekrozemberczki/CapsGNN">Capsule Graph Neural Network</a></li>
<li><a href="https://github.com/benedekrozemberczki/Splitter">Splitter: Learning Node Representations that Capture Multiple Social Contexts</a></li>
<li><a href="https://github.com/benedekrozemberczki/MixHop-and-N-GCN">A Higher-Order Graph Convolutional Layer</a></li>
<li><a href="https://github.com/benedekrozemberczki/APPNP">Predict then Propagate: Graph Neural Networks meet Personalized PageRank</a></li>
<li><a href="https://github.com/theSage21/lorentz-embeddings">Lorentz Embeddings: Learn Continuous Hierarchies in Hyperbolic Space</a></li>
<li><a href="https://github.com/benedekrozemberczki/GraphWaveletNeuralNetwork">Graph Wavelet Neural Network</a></li>
<li><a href="https://github.com/benedekrozemberczki/AttentionWalk">Watch Your Step: Learning Node Embeddings via Graph Attention</a></li>
<li><a href="https://github.com/benedekrozemberczki/SGCN">Signed Graph Convolutional Network</a></li>
<li><a href="https://github.com/benedekrozemberczki/GAM">Graph Classification Using Structural Attention</a></li>
<li><a href="https://github.com/benedekrozemberczki/SimGNN">SimGNN: A Neural Network Approach to Fast Graph Similarity Computation</a></li>
<li><a href="https://github.com/benedekrozemberczki/SINE">SINE: Scalable Incomplete Network Embedding</a></li>
<li><a href="https://github.com/ibalazevic/HypER">HypER: Hypernetwork Knowledge Graph Embeddings</a></li>
<li><a href="https://github.com/ibalazevic/TuckER">TuckER: Tensor Factorization for Knowledge Graph Completion</a></li>
</ul>
<h2 id="sorting">Sorting<a class="headerlink" href="#sorting" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/ermongroup/neuralsort">Stochastic Optimization of Sorting Networks via Continuous Relaxations</a></li>
</ul>
<h2 id="multi-task-learning">Multi-task Learning<a class="headerlink" href="#multi-task-learning" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/huggingface/hmtl">Hierarchical Multi-Task Learning Model</a></li>
<li><a href="https://github.com/locuslab/e2e-model-learning">Task-based End-to-end Model Learning</a></li>
</ul>
<h2 id="gans-vaes-and-aes">GANs, VAEs, and AEs<a class="headerlink" href="#gans-vaes-and-aes" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/DuaneNielsen/DeepInfomaxPytorch">Learning deep representations by mutual information estimation and maximization</a></li>
<li><a href="https://github.com/yookoon/VLAE">Variational Laplace Autoencoders</a></li>
<li><a href="https://github.com/unit8co/vegans">VeGANS, library for easily training GANs</a></li>
<li><a href="https://github.com/github-pengge/PyTorch-progressive_growing_of_gans">Progressive Growing of GANs for Improved Quality, Stability, and Variation</a></li>
<li><a href="https://github.com/kmualim/CGAN-Pytorch/">Conditional GAN</a></li>
<li><a href="https://github.com/martinarjovsky/WassersteinGAN">Wasserstein GAN</a></li>
<li><a href="https://github.com/DmitryUlyanov/AGE">Adversarial Generator-Encoder Network</a></li>
<li><a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">Image-to-Image Translation with Conditional Adversarial Networks</a></li>
<li><a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</a></li>
<li><a href="https://github.com/stormraiser/GAN-weight-norm">On the Effects of Batch and Weight Normalization in Generative Adversarial Networks</a></li>
<li><a href="https://github.com/jalola/improved-wgan-pytorch">Improved Training of Wasserstein GANs</a></li>
<li><a href="https://github.com/wiseodd/generative-models">Collection of Generative Models with PyTorch</a><ul>
<li>Generative Adversarial Nets (GAN)<ol>
<li><a href="https://arxiv.org/abs/1406.2661">Vanilla GAN</a></li>
<li><a href="https://arxiv.org/abs/1411.1784">Conditional GAN</a></li>
<li><a href="https://arxiv.org/abs/1606.03657">InfoGAN</a></li>
<li><a href="https://arxiv.org/abs/1701.07875">Wasserstein GAN</a></li>
<li><a href="https://arxiv.org/abs/1612.02136">Mode Regularized GAN</a></li>
</ol>
</li>
<li>Variational Autoencoder (VAE)<ol>
<li><a href="https://arxiv.org/abs/1312.6114">Vanilla VAE</a></li>
<li><a href="https://arxiv.org/abs/1406.5298">Conditional VAE</a></li>
<li><a href="https://arxiv.org/abs/1511.06406">Denoising VAE</a></li>
<li><a href="https://arxiv.org/abs/1511.05644">Adversarial Autoencoder</a></li>
<li><a href="https://arxiv.org/abs/1701.04722">Adversarial Variational Bayes</a></li>
</ol>
</li>
</ul>
</li>
<li><a href="https://github.com/caogang/wgan-gp">Improved Training of Wasserstein GANs</a></li>
<li><a href="https://github.com/yunjey/mnist-svhn-transfer">CycleGAN and Semi-Supervised GAN</a></li>
<li><a href="https://github.com/jmtomczak/vae_vpflows">Improving Variational Auto-Encoders using Householder Flow and using convex combination linear Inverse Autoregressive Flow</a></li>
<li><a href="https://github.com/znxlwm/pytorch-generative-model-collections">PyTorch GAN Collection</a></li>
<li><a href="https://github.com/jayleicn/animeGAN">Generative Adversarial Networks, focusing on anime face drawing</a></li>
<li><a href="https://github.com/mailmahee/pytorch-generative-adversarial-networks">Simple Generative Adversarial Networks</a></li>
<li><a href="https://github.com/fducau/AAE_pytorch">Adversarial Auto-encoders</a></li>
<li><a href="https://github.com/torchgan/torchgan">torchgan: Framework for modelling Generative Adversarial Networks in Pytorch</a></li>
</ul>
<h2 id="adversarial-attacks">Adversarial Attacks<a class="headerlink" href="#adversarial-attacks" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/utkuozbulak/pytorch-cnn-adversarial-attacks">Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images</a></li>
<li><a href="https://github.com/utkuozbulak/pytorch-cnn-adversarial-attacks">Explaining and Harnessing Adversarial Examples</a></li>
<li><a href="https://github.com/BorealisAI/advertorch">AdverTorch - A Toolbox for Adversarial Robustness Research</a></li>
</ul>
<h2 id="style-transfer">Style Transfer<a class="headerlink" href="#style-transfer" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/StephanZheng/neural-fingerprinting">Detecting Adversarial Examples via Neural Fingerprinting</a></li>
<li><a href="https://github.com/alexis-jacq/Pytorch-Tutorials">A Neural Algorithm of Artistic Style</a></li>
<li><a href="https://github.com/zhanghang1989/PyTorch-Style-Transfer">Multi-style Generative Network for Real-time Transfer</a></li>
<li><a href="https://github.com/jantic/DeOldify">DeOldify, Coloring Old Images</a></li>
<li><a href="https://github.com/ProGamerGov/neural-style-pt">Neural Style Transfer</a></li>
<li><a href="https://github.com/darkstar112358/fast-neural-style">Fast Neural Style Transfer</a></li>
<li><a href="https://github.com/kendricktan/drawlikebobross">Draw like Bob Ross</a></li>
</ul>
<h2 id="image-captioning">Image Captioning<a class="headerlink" href="#image-captioning" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/ruotianluo/neuraltalk2.pytorch">Neuraltalk 2, Image Captioning Model, in PyTorch</a></li>
<li><a href="https://github.com/eladhoffer/captionGen">Generate captions from an image with PyTorch</a></li>
</ul>
<h2 id="transformers">Transformers<a class="headerlink" href="#transformers" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/jadore801120/attention-is-all-you-need-pytorch">Attention is all you need</a></li>
<li><a href="https://github.com/fxia22/stn.pytorch">Spatial Transformer Networks</a></li>
</ul>
<h2 id="similarity-networks-and-functions">Similarity Networks and Functions<a class="headerlink" href="#similarity-networks-and-functions" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/andreasveit/conditional-similarity-networks">Conditional Similarity Networks</a></li>
</ul>
<h2 id="reasoning">Reasoning<a class="headerlink" href="#reasoning" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/facebookresearch/clevr-iep">Inferring and Executing Programs for Visual Reasoning</a></li>
</ul>
<h2 id="general-nlp">General NLP<a class="headerlink" href="#general-nlp" title="Permanent link"></a></h2>
<ul>
<li>[<a href="https://github.com/HX-idiot/Hybrid_Attention_XML">https://github.com/HX-idiot/Hybrid_Attention_XML</a>]</li>
<li><a href="https://github.com/graykode/xlnet-Pytorch">XLNet</a></li>
<li><a href="https://github.com/qkaren/converse_reading_cmr">Conversing by Reading: Contentful Neural Conversation with On-demand Machine Reading</a></li>
<li><a href="https://github.com/facebookresearch/XLM">Cross-lingual Language Model Pretraining</a></li>
<li><a href="https://github.com/lernapparat/lotranslate">Libre Office Translate via PyTorch NMT</a></li>
<li><a href="https://github.com/huggingface/pytorch-pretrained-BERT">BERT</a></li>
<li><a href="https://github.com/fartashf/vsepp">VSE++: Improved Visual-Semantic Embeddings</a></li>
<li><a href="https://github.com/ExplorerFreda/Structured-Self-Attentive-Sentence-Embedding">A Structured Self-Attentive Sentence Embedding</a></li>
<li><a href="https://github.com/jiesutd/PyTorchSeqLabel">Neural Sequence labeling model</a></li>
<li><a href="https://github.com/sanyam5/skip-thoughts">Skip-Thought Vectors</a></li>
<li><a href="https://github.com/eladhoffer/seq2seq.pytorch">Complete Suite for Training Seq2Seq Models in PyTorch</a></li>
<li><a href="https://github.com/facebookresearch/MUSE">MUSE: Multilingual Unsupervised and Supervised Embeddings</a></li>
</ul>
<h2 id="question-and-answering">Question and Answering<a class="headerlink" href="#question-and-answering" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/Cadene/vqa.pytorch">Visual Question Answering in Pytorch</a></li>
<li><a href="https://github.com/facebookresearch/DrQA">Reading Wikipedia to Answer Open-Domain Questions</a></li>
<li><a href="https://github.com/facebookresearch/end-to-end-negotiator">Deal or No Deal? End-to-End Learning for Negotiation Dialogues</a></li>
<li><a href="https://github.com/sanyam5/irlc-vqa">Interpretable Counting for Visual Question Answering</a></li>
<li><a href="https://github.com/jinfagang/pytorch_chatbot">Open Source Chatbot with PyTorch</a></li>
</ul>
<h2 id="speech-generation-and-recognition">Speech Generation and Recognition<a class="headerlink" href="#speech-generation-and-recognition" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/mravanelli/pytorch-kaldi">PyTorch-Kaldi Speech Recognition Toolkit</a></li>
<li><a href="https://github.com/NVIDIA/waveglow">WaveGlow: A Flow-based Generative Network for Speech Synthesis</a></li>
<li><a href="https://github.com/OpenNMT/OpenNMT-py">OpenNMT</a></li>
<li><a href="https://github.com/SeanNaren/deepspeech.pytorch">Deep Speech 2: End-to-End Speech Recognition in English and Mandarin</a></li>
</ul>
<h2 id="document-and-text-classification">Document and Text Classification<a class="headerlink" href="#document-and-text-classification" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/cedias/HAN-pytorch">Hierarchical Attention Network for Document Classification</a></li>
<li><a href="https://github.com/EdGENetworks/attention-networks-for-classification">Hierarchical Attention Networks for Document Classification</a></li>
<li><a href="https://github.com/xiayandi/Pytorch_text_classification">CNN Based Text Classification</a></li>
</ul>
<h2 id="text-generation">Text Generation<a class="headerlink" href="#text-generation" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/jhave/pytorch-poetry-generation">Pytorch Poetry Generation</a></li>
</ul>
<h2 id="translation">Translation<a class="headerlink" href="#translation" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/OpenNMT/OpenNMT-py">Open-source (MIT) Neural Machine Translation (NMT) System</a></li>
</ul>
<h2 id="sentiment-analysis">Sentiment Analysis<a class="headerlink" href="#sentiment-analysis" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/vanzytay/pytorch_sentiment_rnn">Recurrent Neural Networks for Sentiment Analysis (Aspect-Based) on SemEval 2014</a></li>
<li><a href="https://github.com/spro/pytorch-seq2seq-intent-parsing">Seq2Seq Intent Parsing</a></li>
</ul>
<h2 id="deep-reinforcement-learning">Deep Reinforcement Learning<a class="headerlink" href="#deep-reinforcement-learning" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/IC3Net/IC3Net">Learning when to communicate at scale in multiagent cooperative and competitive tasks</a></li>
<li><a href="https://github.com/shariqiqbal2810/MAAC">Actor-Attention-Critic for Multi-Agent Reinforcement Learning</a></li>
<li><a href="https://github.com/mhubii/ppo_pytorch_cpp">PPO in PyTorch C++</a></li>
<li><a href="https://github.com/khanhptnk/bandit-nmt">Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback</a></li>
<li><a href="https://github.com/ikostrikov/pytorch-a3c">Asynchronous Methods for Deep Reinforcement Learning</a></li>
<li><a href="https://github.com/ikostrikov/pytorch-naf">Continuous Deep Q-Learning with Model-based Acceleration</a></li>
<li><a href="https://github.com/dgriff777/rl_a3c_pytorch">Asynchronous Methods for Deep Reinforcement Learning for Atari 2600</a></li>
<li><a href="https://github.com/mjacar/pytorch-trpo">Trust Region Policy Optimization</a></li>
<li><a href="https://github.com/pemami4911/neural-combinatorial-rl-pytorch">Neural Combinatorial Optimization with Reinforcement Learning</a></li>
<li><a href="https://github.com/Kaixhin/NoisyNet-A3C">Noisy Networks for Exploration</a></li>
<li><a href="https://github.com/alexis-jacq/Pytorch-DPPO">Distributed Proximal Policy Optimization</a></li>
<li><a href="https://github.com/akolishchak/doom-net-pytorch">Reinforcement learning models in ViZDoom environment with PyTorch</a></li>
<li><a href="https://github.com/jingweiz/pytorch-rl">Reinforcement learning models using Gym and Pytorch</a></li>
<li><a href="https://github.com/kengz/SLM-Lab">SLM-Lab: Modular Deep Reinforcement Learning framework in PyTorch</a></li>
</ul>
<h2 id="deep-bayesian-learning-and-probabilistic-programmming">Deep Bayesian Learning and Probabilistic Programmming<a class="headerlink" href="#deep-bayesian-learning-and-probabilistic-programmming" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/wjmaddox/drbayes">Subspace Inference for Bayesian Deep Learning</a></li>
<li><a href="https://github.com/ctallec/pyvarinf">Bayesian Deep Learning with Variational Inference Package</a></li>
<li><a href="https://github.com/stepelu/ptstat">Probabilistic Programming and Statistical Inference in PyTorch</a></li>
<li><a href="https://github.com/kumar-shridhar/PyTorch-BayesianCNN">Bayesian CNN with Variational Inferece in PyTorch</a></li>
</ul>
<h2 id="anomaly-detection">Anomaly Detection<a class="headerlink" href="#anomaly-detection" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/GitiHubi/deepAI">Detection of Accounting Anomalies using Deep Autoencoder Neural Networks</a></li>
</ul>
<h2 id="regression-types">Regression Types<a class="headerlink" href="#regression-types" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/ars-ashuha/quantile-regression-dqn-pytorch">Quantile Regression DQN</a></li>
</ul>
<h2 id="time-series">Time Series<a class="headerlink" href="#time-series" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/tejaslodaya/timeseries-clustering-vae">Variational Recurrent Autoencoder for Timeseries Clustering</a></li>
<li><a href="https://github.com/edouardelasalles/stnn">Spatio-Temporal Neural Networks for Space-Time Series Modeling and Relations Discovery</a></li>
</ul>
<h2 id="neural-network-general-improvements">Neural Network General Improvements<a class="headerlink" href="#neural-network-general-improvements" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/mapillary/inplace_abn">In-Place Activated BatchNorm for Memory-Optimized Training of DNNs</a></li>
<li><a href="https://github.com/eladhoffer/bigBatch">Train longer, generalize better: closing the generalization gap in large batch training of neural networks</a></li>
<li><a href="https://github.com/ajbrock/FreezeOut">FreezeOut: Accelerate Training by Progressively Freezing Layers</a></li>
<li><a href="https://github.com/Wizaron/binary-stochastic-neurons">Binary Stochastic Neurons</a></li>
<li><a href="https://github.com/DeepInsight-PCALab/CompactBilinearPooling-Pytorch">Compact Bilinear Pooling</a></li>
<li><a href="https://github.com/suvojit-0x55aa/mixed-precision-pytorch">Mixed Precision Training in PyTorch</a></li>
</ul>
<h2 id="dnn-applications-in-chemistry-and-physics">DNN Applications in Chemistry and Physics<a class="headerlink" href="#dnn-applications-in-chemistry-and-physics" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/fancompute/wavetorch">Wave Physics as an Analog Recurrent Neural Network</a></li>
<li><a href="https://github.com/priba/nmp_qc">Neural Message Passing for Quantum Chemistry</a></li>
<li><a href="https://github.com/cxhernandez/molencoder">Automatic chemical design using a data-driven continuous representation of molecules</a></li>
<li><a href="https://github.com/emited/flow">Deep Learning for Physical Processes: Integrating Prior Scientific Knowledge</a></li>
</ul>
<h2 id="new-thinking-on-general-neural-network-architecture">New Thinking on General Neural Network Architecture<a class="headerlink" href="#new-thinking-on-general-neural-network-architecture" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/andrewliao11/dni.pytorch">Decoupled Neural Interfaces using Synthetic Gradients</a></li>
</ul>
<h2 id="to-be-classified">To be Classified<a class="headerlink" href="#to-be-classified" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/michaelklachko/pnn.pytorch">Perturbative Neural Networks</a></li>
<li><a href="https://github.com/aiqm/torchani">Accurate Neural Network Potential</a></li>
<li><a href="https://github.com/edouardoyallon/pyscatwave">Scaling the Scattering Transform: Deep Hybrid Networks</a></li>
<li><a href="https://github.com/e-lab/pytorch-CortexNet">CortexNet: a Generic Network Family for Robust Visual Temporal Representations</a></li>
<li><a href="https://github.com/ZhouYanzhao/ORN">Oriented Response Networks</a></li>
<li><a href="https://github.com/jalexvig/associative_compression_networks">Associative Compression Networks</a></li>
<li><a href="https://github.com/ksw0306/ClariNet">Clarinet</a></li>
<li><a href="https://github.com/tomrunia/PyTorchWavelets">Continuous Wavelet Transforms</a></li>
<li><a href="https://github.com/leehomyc/mixup_pytorch">mixup: Beyond Empirical Risk Minimization</a></li>
<li><a href="https://github.com/szagoruyko/functional-zoo">Network In Network</a></li>
<li><a href="https://github.com/c0nn3r/pytorch_highway_networks">Highway Networks</a></li>
<li><a href="https://github.com/ypxie/pytorch-NeuCom">Hybrid computing using a neural network with dynamic external memory</a></li>
<li><a href="https://github.com/onlytailei/PyTorch-value-iteration-networks">Value Iteration Networks</a></li>
<li><a href="https://github.com/jingweiz/pytorch-dnc">Differentiable Neural Computer</a></li>
<li><a href="https://github.com/alexis-jacq/Pytorch-Sketch-RNN">A Neural Representation of Sketch Drawings</a></li>
<li><a href="https://github.com/utkuozbulak/pytorch-cnn-visualizations">Understanding Deep Image Representations by Inverting Them</a></li>
<li><a href="https://github.com/truskovskiyk/nima.pytorch">NIMA: Neural Image Assessment</a></li>
<li><a href="https://github.com/veronikayurchuk/pretrained-models.pytorch">NASNet-A-Mobile. Ported weights</a></li>
<li><a href="https://github.com/jtoy/sketchnet">Graphics code generating model using Processing</a></li>
</ul>
<h2 id="low-level-utilities">Low Level Utilities<a class="headerlink" href="#low-level-utilities" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/interesaaat/TorchSharp">TorchSharp, .NET API with access to underlying library powering PyTorch</a></li>
</ul>
<h2 id="pytorch-utilities">PyTorch Utilities<a class="headerlink" href="#pytorch-utilities" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/awwong1/torchprof">Layer-by-layer PyTorch Model Profiler for Checking Model Time Consumption</a></li>
<li><a href="https://github.com/probabll/sparse-distributions">Sparse Distributions</a></li>
<li><a href="https://github.com/ag14774/diffdist">Diffdist, Adds Support for Differentiable Communication allowing distributed model parallelism</a></li>
<li><a href="https://github.com/amirgholami/HessianFlow">HessianFlow, Library for Hessian Based Algorithms</a></li>
<li><a href="https://github.com/asyml/texar-pytorch">Texar, PyTorch Toolkit for Text Generation</a></li>
<li><a href="https://github.com/Lyken17/pytorch-OpCounter">PyTorch FLOPs counter</a></li>
<li><a href="https://github.com/zccyman/pytorch-inference">PyTorch Inference on C++ in Windows</a></li>
<li><a href="https://github.com/perone/euclidesdb">EuclidesDB, Multi-Model Machine Learning Feature Database</a></li>
<li><a href="https://github.com/ncullen93/torchsample">Data Augmentation and Sampling for Pytorch</a></li>
<li><a href="https://github.com/facebookresearch/pytext">PyText, deep learning based NLP modelling framework officially maintained by FAIR</a></li>
<li><a href="https://github.com/Swall0w/torchstat">Torchstat for Statistics on PyTorch Models</a></li>
<li><a href="https://github.com/pytorch/audio">Load Audio files directly into PyTorch Tensors</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/master/torch/nn/init.py">Weight Initializations</a></li>
<li><a href="https://github.com/fxia22/stn.pytorch">Spatial transformer implemented in PyTorch</a></li>
<li><a href="https://github.com/ritchieng/dlami">PyTorch AWS AMI, run PyTorch with GPU support in less than 5 minutes</a></li>
<li><a href="https://github.com/lanpa/tensorboard-pytorch">Use tensorboard with PyTorch</a></li>
<li><a href="https://github.com/henryre/pytorch-fitmodule">Simple Fit Module in PyTorch, similar to Keras</a></li>
<li><a href="https://github.com/ecs-vlc/torchbearer">torchbearer: A model fitting library for PyTorch</a></li>
<li><a href="https://github.com/nerox8664/pytorch2keras">PyTorch to Keras model converter</a></li>
<li><a href="https://github.com/nerox8664/gluon2pytorch">Gluon to PyTorch model converter with code generation</a></li>
</ul>
<h2 id="pytorch-video-tutorials">PyTorch Video Tutorials<a class="headerlink" href="#pytorch-video-tutorials" title="Permanent link"></a></h2>
<ul>
<li><a href="https://www.udemy.com/practical-deep-learning-with-pytorch/?couponCode=DEEPWIZARD">Practical Deep Learning with PyTorch</a></li>
<li><a href="http://bit.ly/PyTorchVideo">PyTorch Zero to All Lectures</a></li>
</ul>
<h2 id="datasets">Datasets<a class="headerlink" href="#datasets" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/mwouts/world_bank_data">Worldbank Data</a></li>
</ul>
<h2 id="community">Community<a class="headerlink" href="#community" title="Permanent link"></a></h2>
<ul>
<li><a href="https://discuss.pytorch.org/">PyTorch Discussion Forum</a></li>
<li><a href="http://stackoverflow.com/questions/tagged/pytorch">StackOverflow PyTorch Tags</a></li>
</ul>
<h2 id="links-to-this-repository">Links to This Repository<a class="headerlink" href="#links-to-this-repository" title="Permanent link"></a></h2>
<ul>
<li><a href="https://github.com/ritchieng/the-incredible-pytorch">Github Repository</a></li>
<li><a href="https://www.ritchieng.com/the-incredible-pytorch/">Website</a></li>
</ul>
<h2 id="contributions">Contributions<a class="headerlink" href="#contributions" title="Permanent link"></a></h2>
<p>Do feel free to contribute!</p>
<p>You can raise an issue or submit a pull request, whichever is more convenient for you. The guideline is simple: just follow the format of the previous bullet point.</p></article></body></html>